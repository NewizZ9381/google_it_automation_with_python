{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Slowness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top : CPU/ memory\n",
    "iotop : disk io usage\n",
    "iftop : network bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ab -n 500 site.example.com/\n",
    "ssh webserver\n",
    "clear\n",
    "top\n",
    "q\n",
    "\n",
    "nice : set priority 0-19 (0 is the most priority)\n",
    "renice : change priority\n",
    "pidof\n",
    "\n",
    "for pid in $(pidof ffmpeg); do renice 19 $pid; done\n",
    "\n",
    "ps ax\n",
    "less\n",
    "\n",
    "ps ax | less\n",
    "/ffmpeg\n",
    "locate static/001.webm\n",
    "cd /srv/deploy_videos/\n",
    "ls -l\n",
    "grep ffmpeg *\n",
    "vim deploy.sh\n",
    "delete daemonize\n",
    "\n",
    "clear\n",
    "killall -STOP ffmpeg\n",
    "for pid in $(pidof ffmpeg); do while kill -CONT $pid; dp sleep 1; done; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slow Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gprof : C program\n",
    "Cprofile : Python program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List : fast for add/remove data at the end\n",
    "        fast for retrieve data from index\n",
    "        slow for add data in the middel\n",
    "        slow for retrieve data from unknown position\n",
    "* If you need to access elements by position, or will always iterate through all the elements, use a list to store them\n",
    "       \n",
    "Dictionary (Hash/map) : fast to find key value in one operation\n",
    "* If we need to loop up the elements using a key, we'll use a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do an expensive operation inside a loop, you multiply the time it takes to do the expensive operation by the amount of times you repeat the loop.\n",
    "Make sure that the list of elements that you're iterating through is only as long as you really need it to be.\n",
    "Another thing to remember about loops is to break out of the loop once you've found what you were looking for. (break)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time ./send_reminders.py \"2020-01-13|Example|test1\"\n",
    "\n",
    "Real : The amount of actual time that it took to execute the command (Wall-clock time)\n",
    "User : The time spent doing operations in the user space\n",
    "Sys : the time spent doing system-level operations\n",
    "\n",
    "time ./send_reminders.py \"2020-01-13|Example|test1,test2,test3,test4,test5,test6,test7,test8,test9\"\n",
    "\n",
    "pprofile3 -f callgrind -o profile.out ./send_reminders.py \"2020-01-13|Example|test1,test2,test3,test4,test5,test6,test7,test8,test9\"\n",
    "\n",
    "kcachegrind profile.out\n",
    "clear\n",
    "atom send_reminders.py\n",
    "get_name function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When Slowness Problems Get Complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python : Module Threading/ AsyncIO These modules let us specify which parts of the code we want to run in separate threads or as separate asynchronous events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import future\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def process_options():\n",
    "\n",
    "    kwargs = {\n",
    "        'format': '[%(levelname)s] %(message)s',\n",
    "    }\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Thumbnail generator',\n",
    "        fromfile_prefix_chars='@'\n",
    "    )\n",
    "    parser.add_argument('--debug', action='store_true')\n",
    "    parser.add_argument('-v', '--verbose', action='store_true')\n",
    "    parser.add_argument('-q', '--quiet', action='store_true')\n",
    "\n",
    "    options = parser.parse_args()\n",
    "\n",
    "    if options.debug:\n",
    "        kwargs['level'] = logging.DEBUG\n",
    "    elif options.verbose:\n",
    "        kwargs['level'] = logging.INFO\n",
    "    elif options.quiet:\n",
    "        kwargs['level'] = logging.ERROR\n",
    "    else:\n",
    "        kwargs['level'] = logging.WARN\n",
    "\n",
    "    logging.basicConfig(**kwargs)\n",
    "\n",
    "    return options\n",
    "\n",
    "\n",
    "def process_file(root, basename):\n",
    "    filename = f'{root}/{basename}'\n",
    "    image = PIL.Image.open(filename)\n",
    "\n",
    "    size = (128, 128)\n",
    "    image.thumbnail(size)\n",
    "\n",
    "    new_name = f'thumbnails/{basename}'\n",
    "    image.save(new_name, \"JPEG\")\n",
    "    return new_name\n",
    "\n",
    "\n",
    "def progress_bar(files):\n",
    "    return tqdm(files, desc='Processing', total=len(files), dynamic_ncols=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    process_options()\n",
    "\n",
    "    # Create the thumbnails directory\n",
    "    if not os.path.exists('thumbnails'):\n",
    "        os.mkdir('thumbnails')\n",
    "\n",
    "#     executor - futures.ThreadPoolExecutor()\n",
    "    executor - futures.ProcessPoolExecutor()\n",
    "    for root, _, files in os.walk('images'):\n",
    "        for basename in progress_bar(files):\n",
    "            if not basename.endswith('.jpg'):\n",
    "                continue\n",
    "            executor.submit(process_file, root, basename)\n",
    "#             process_file(root, basename)\n",
    "    print(\"Waiting for all threads to finish.\")\n",
    "    executor.shutdown()\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executor : The process that's in charge of distributing the work among the different workers\n",
    "Futures modeul : Provides a couple of different executors; one for using threads and another for using processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threads use a bunch of safety features to avoid having two threads that try to write to the same variable. And this means that when using threads, they may end up waiting for their turn to write to variables for a few milliseconds, adding up to the small difference between the two approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a slow system with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo apt install python3-pip\n",
    "pip3 install psutil\n",
    "python3\n",
    "import psutil\n",
    "psutil.cpu_percent()\n",
    "psutil.disk_io_counters()\n",
    "psutil.net_io_counters()\n",
    "\n",
    "rsync [Options] [Source-Files-Dir] [Destination]\n",
    "rsync -zvh [Source-Files-Dir] [Destination]\n",
    "rsync -zavh [Source-Files-Dir] [Destination]\n",
    "rsync -zrvh [Source-Files-Dir] [Destination]\n",
    "\n",
    "python3\n",
    "import subprocess\n",
    "src = \"<source-path>\" # replace <source-path> with the source directory\n",
    "dest = \"<destination-path>\" # replace <destination-path> with the destination directory\n",
    "subprocess.call([\"rsync\", \"-arq\", src, dest])\n",
    "    \n",
    "ls ~/scripts\n",
    "sudo chmod +x ~/scripts/multisync.py\n",
    "./scripts/multisync.py\n",
    "\n",
    "nano ~/scripts/dailysync.py\n",
    "sudo chmod +x ~/scripts/dailysync.py\n",
    "./scripts/dailysync.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multisync.py\n",
    "#!/usr/bin/env python3\n",
    "from multiprocessing import Pool\n",
    "def run(task):\n",
    "  # Do something with task here\n",
    "    print(\"Handling {}\".format(task))\n",
    "if __name__ == \"__main__\":\n",
    "  tasks = ['task1', 'task2', 'task3']\n",
    "  # Create a pool of specific number of CPUs\n",
    "  p = Pool(len(tasks))\n",
    "  # Start each task within the pool\n",
    "  p.map(run, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dailysync.py\n",
    "#!/usr/bin/env python\n",
    "import subprocess\n",
    "src = \"/data/prod/\"\n",
    "dest = \"/data/prod_backup/\"\n",
    "subprocess.call([\"rsync\", \"-arq\", src, dest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import subprocess\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "def backup(src):\n",
    "    dest = os.getcwd() + \"/data/prod_backup/\"\n",
    "    print(\"Backing up {} into {}\".format(src, dest))\n",
    "    subprocess.call([\"rsync\", \"-arq\", src, dest])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    src = os.getcwd() + \"/data/prod/\"\n",
    "    list_of_files = os.listdir(src)\n",
    "    all_files = []\n",
    "\n",
    "    for value in list_of_files:\n",
    "        full_path = os.path.join(src, value)\n",
    "        all_files.append(full_path)\n",
    "\n",
    "#     with Pool(len(all_files)) as pool:\n",
    "        pool = Pool(len(all_files))\n",
    "        pool.map(backup, all_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
